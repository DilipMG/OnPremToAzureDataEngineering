{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "234daafd-ba5b-47a2-8aff-e349580896dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Connecting ADLS Gen2 with Azure Databricks Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51172db-f931-4355-bc00-e9129a1ba7e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Created the App Registration in Azure Portal. \n",
    "2. Created the Secret under Certificate&Secrets for the App Registration that is created\n",
    "3. In ADLS2, under IAM -> Added new Role Assignment and add the User that is created in the App Registration to establish the connectivity between ADLS and Azure Databricks. \n",
    "'''\n",
    "\n",
    "storage_account = \"dmgproductionadls2\"                     # Storage account name\n",
    "application_id = \"7729fa92-7775-4604-9238-20b3d90fdecf\"    # Application ID from App Registration\n",
    "directory_id = \"72a18fcd-e918-4ce9-aea4-0d2739f1bc60\"      # Directory ID from App Registration\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", application_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", \"BtG8Q~xXGHe18fHgNtggNyDHcJuxSgOun1kagdBE\")                # Value from App Registration -> Certification & Secrets\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3261217-5fc8-4dbc-8442-74c62dd98ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Accessing the bronze layer and getting all the files names for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47ccbf33-956c-4b99-a464-52143692af31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CountryRegionCurrency/', 'CreditCard/', 'Currency/', 'CurrencyRate/', 'Customer/', 'PersonCreditCard/', 'SalesOrderDetail/', 'SalesOrderHeader/', 'SalesOrderHeaderSalesReason/', 'SalesPerson/', 'SalesPersonQuotaHistory/', 'SalesReason/', 'SalesTaxRate/', 'SalesTerritory/', 'SalesTerritoryHistory/', 'ShoppingCartItem/', 'SpecialOffer/', 'SpecialOfferProduct/', 'Store/']\n"
     ]
    }
   ],
   "source": [
    "# Extracting the bronze layered table list\n",
    "bronze_base_path = 'abfss://bronze@dmgproductionadls2.dfs.core.windows.net/Sales/'\n",
    "dbutils.fs.ls(bronze_base_path)\n",
    "tables_list=[]\n",
    "for table in dbutils.fs.ls(bronze_base_path):\n",
    "    tables_list.append(table.name)\n",
    "print(tables_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d82d6a7-1c00-4965-a4fd-243c7da8101d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Reading the Bronze layer files into Spark dataframes dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13d48f4c-7963-46fb-9aef-581dfa60e14c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the dataframe is df_CountryRegionCurrency and count is 109\n+-----------------+------------+--------------------+\n|CountryRegionCode|CurrencyCode|        ModifiedDate|\n+-----------------+------------+--------------------+\n|               AE|         AED|2014-02-08 10:17:...|\n|               AR|         ARS|2014-02-08 10:17:...|\n+-----------------+------------+--------------------+\nonly showing top 2 rows\n\nThe data is:\n None\nThe name of the dataframe is df_CreditCard and count is 19118\n+------------+------------+--------------+--------+-------+-------------------+\n|CreditCardID|    CardType|    CardNumber|ExpMonth|ExpYear|       ModifiedDate|\n+------------+------------+--------------+--------+-------+-------------------+\n|           1|SuperiorCard|33332664695310|      11|   2006|2013-07-29 00:00:00|\n|           2| Distinguish|55552127249722|       8|   2005|2013-12-05 00:00:00|\n+------------+------------+--------------+--------+-------+-------------------+\nonly showing top 2 rows\n\nThe data is:\n None\nThe name of the dataframe is df_Currency and count is 105\n+------------+--------------+-------------------+\n|CurrencyCode|          Name|       ModifiedDate|\n+------------+--------------+-------------------+\n|         AED|Emirati Dirham|2008-04-30 00:00:00|\n|         AFA|       Afghani|2008-04-30 00:00:00|\n+------------+--------------+-------------------+\nonly showing top 2 rows\n\nThe data is:\n None\nThe name of the dataframe is df_CurrencyRate and count is 13532\n+--------------+-------------------+----------------+--------------+-----------+------------+-------------------+\n|CurrencyRateID|   CurrencyRateDate|FromCurrencyCode|ToCurrencyCode|AverageRate|EndOfDayRate|       ModifiedDate|\n+--------------+-------------------+----------------+--------------+-----------+------------+-------------------+\n|             1|2011-05-31 00:00:00|             USD|           ARS|     1.0000|      1.0002|2011-05-31 00:00:00|\n|             2|2011-05-31 00:00:00|             USD|           AUD|     1.5491|      1.5500|2011-05-31 00:00:00|\n+--------------+-------------------+----------------+--------------+-----------+------------+-------------------+\nonly showing top 2 rows\n\nThe data is:\n None\nThe name of the dataframe is df_Customer and count is 19820\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\n|CustomerID|PersonID|StoreID|TerritoryID|AccountNumber|             rowguid|        ModifiedDate|\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\n|         1|    NULL|    934|          1|   AW00000001|3f5ae95e-b87d-4ae...|2014-09-12 11:15:...|\n|         2|    NULL|   1028|          1|   AW00000002|e552f657-a9af-4a7...|2014-09-12 11:15:...|\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\nonly showing top 2 rows\n\nThe data is:\n None\nThe name of the dataframe is df_PersonCreditCard and count is 19118\n+----------------+------------+-------------------+\n|BusinessEntityID|CreditCardID|       ModifiedDate|\n+----------------+------------+-------------------+\n|             293|       17038|2013-07-31 00:00:00|\n|             295|       15369|2011-08-01 00:00:00|\n+----------------+------------+-------------------+\nonly showing top 2 rows\n\nThe data is:\n None\nThe name of the dataframe is df_SalesOrderDetail and count is 121317\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\n|SalesOrderID|SalesOrderDetailID|CarrierTrackingNumber|OrderQty|ProductID|SpecialOfferID|UnitPrice|UnitPriceDiscount|  LineTotal|             rowguid|       ModifiedDate|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\n|       43659|                 1|         4911-403C-98|       1|      776|             1|2024.9940|           0.0000|2024.994000|b207c96d-d9e6-402...|2011-05-31 00:00:00|\n|       43659|                 2|         4911-403C-98|       3|      777|             1|2024.9940|           0.0000|6074.982000|7abb600d-1e77-41b...|2011-05-31 00:00:00|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\nonly showing top 2 rows\n\nThe data is:\n None\n"
     ]
    }
   ],
   "source": [
    "# Extracting the data from Bronze layer into dataframes inside a dictionary. \n",
    "df={}\n",
    "for table in tables_list:\n",
    "    file_name=table.split(\"/\")[0]\n",
    "    file_df=\"df_\"+file_name\n",
    "    file_path = bronze_base_path+table+file_name+\".parquet\"\n",
    "    df[file_df]=spark.read.parquet(file_path,header=True)\n",
    "    print(f'The name of the dataframe is {file_df} and count is {df[file_df].count()}')\n",
    "    print(\"The data is:\\n\",df[file_df].show(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbd49985-16c4-45e5-83f5-40ce7948dd6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c91e39b5-7e15-40f6-9616-b7bb0b916264",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Defining the function to check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "618eecb5-b3fd-42c5-b8b1-939901fe02e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8903882494457152>, line 5\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m file_name\u001B[38;5;241m=\u001B[39mtable\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
       "\u001B[1;32m      4\u001B[0m file_df\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdf_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mfile_name\n",
       "\u001B[0;32m----> 5\u001B[0m file_path \u001B[38;5;241m=\u001B[39m base_path\u001B[38;5;241m+\u001B[39mtable\u001B[38;5;241m+\u001B[39mfile_name\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      6\u001B[0m df[file_df]\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mparquet(file_path,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe name of the dataframe is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_df\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and count is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[file_df]\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'base_path' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'base_path' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8903882494457152>, line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m file_name\u001B[38;5;241m=\u001B[39mtable\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      4\u001B[0m file_df\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdf_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mfile_name\n\u001B[0;32m----> 5\u001B[0m file_path \u001B[38;5;241m=\u001B[39m base_path\u001B[38;5;241m+\u001B[39mtable\u001B[38;5;241m+\u001B[39mfile_name\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m df[file_df]\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mparquet(file_path,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe name of the dataframe is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_df\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and count is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[file_df]\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
        "\u001B[0;31mNameError\u001B[0m: name 'base_path' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "def check_nulls(df, df_name):\n",
    "    # Initialize an empty list to store the count expressions\n",
    "    counts = []\n",
    "    \n",
    "    # Iterate over each column and apply the count condition\n",
    "    for c in df.columns:\n",
    "        counts.append(count(when(col(c).isNull(), 1)).alias(c))\n",
    "    \n",
    "    # Apply select with the count expressions\n",
    "    null_counts_df = df.select(*counts)\n",
    "    \n",
    "    # Collect results as a dictionary\n",
    "    null_counts = null_counts_df.collect()[0].asDict()\n",
    "   \n",
    "    # Check if any column has nulls\n",
    "    if any(value > 0 for value in null_counts.values()):\n",
    "        print(f\"!!!!! Null values detected in {df_name}!!!!!\")\n",
    "        print(null_counts)\n",
    "    else:\n",
    "        print(f\"<<OK>> No nulls found in {df_name} <<OK>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d75d46-ac45-4a60-afdf-310722efc0e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe  table is  : df_CountryRegionCurrency\nThe count of df: 109\n<<OK>> No nulls found in df_CountryRegionCurrency <<OK>>\n\nThe  table is  : df_CreditCard\nThe count of df: 19118\n<<OK>> No nulls found in df_CreditCard <<OK>>\n\nThe  table is  : df_Currency\nThe count of df: 105\n<<OK>> No nulls found in df_Currency <<OK>>\n\nThe  table is  : df_CurrencyRate\nThe count of df: 13532\n<<OK>> No nulls found in df_CurrencyRate <<OK>>\n\nThe  table is  : df_Customer\nThe count of df: 19820\n!!!!! Null values detected in df_Customer!!!!!\n{'CustomerID': 0, 'PersonID': 701, 'StoreID': 18484, 'TerritoryID': 0, 'AccountNumber': 0, 'rowguid': 0, 'ModifiedDate': 0}\n\nThe  table is  : df_PersonCreditCard\nThe count of df: 19118\n<<OK>> No nulls found in df_PersonCreditCard <<OK>>\n\nThe  table is  : df_SalesOrderDetail\nThe count of df: 121317\n!!!!! Null values detected in df_SalesOrderDetail!!!!!\n{'SalesOrderID': 0, 'SalesOrderDetailID': 0, 'CarrierTrackingNumber': 60398, 'OrderQty': 0, 'ProductID': 0, 'SpecialOfferID': 0, 'UnitPrice': 0, 'UnitPriceDiscount': 0, 'LineTotal': 0, 'rowguid': 0, 'ModifiedDate': 0}\n\nThe  table is  : df_SalesOrderHeader\nThe count of df: 31465\n!!!!! Null values detected in df_SalesOrderHeader!!!!!\n{'SalesOrderID': 0, 'RevisionNumber': 0, 'OrderDate': 0, 'DueDate': 0, 'ShipDate': 0, 'Status': 0, 'OnlineOrderFlag': 0, 'SalesOrderNumber': 0, 'PurchaseOrderNumber': 27659, 'AccountNumber': 0, 'CustomerID': 0, 'SalesPersonID': 27659, 'TerritoryID': 0, 'BillToAddressID': 0, 'ShipToAddressID': 0, 'ShipMethodID': 0, 'CreditCardID': 1131, 'CreditCardApprovalCode': 1131, 'CurrencyRateID': 17489, 'SubTotal': 0, 'TaxAmt': 0, 'Freight': 0, 'TotalDue': 0, 'Comment': 31465, 'rowguid': 0, 'ModifiedDate': 0}\n\nThe  table is  : df_SalesOrderHeaderSalesReason\nThe count of df: 27647\n<<OK>> No nulls found in df_SalesOrderHeaderSalesReason <<OK>>\n\nThe  table is  : df_SalesPerson\nThe count of df: 17\n!!!!! Null values detected in df_SalesPerson!!!!!\n{'BusinessEntityID': 0, 'TerritoryID': 3, 'SalesQuota': 3, 'Bonus': 0, 'CommissionPct': 0, 'SalesYTD': 0, 'SalesLastYear': 0, 'rowguid': 0, 'ModifiedDate': 0}\n\nThe  table is  : df_SalesPersonQuotaHistory\nThe count of df: 163\n<<OK>> No nulls found in df_SalesPersonQuotaHistory <<OK>>\n\nThe  table is  : df_SalesReason\nThe count of df: 10\n<<OK>> No nulls found in df_SalesReason <<OK>>\n\nThe  table is  : df_SalesTaxRate\nThe count of df: 29\n<<OK>> No nulls found in df_SalesTaxRate <<OK>>\n\nThe  table is  : df_SalesTerritory\nThe count of df: 10\n<<OK>> No nulls found in df_SalesTerritory <<OK>>\n\nThe  table is  : df_SalesTerritoryHistory\nThe count of df: 17\n!!!!! Null values detected in df_SalesTerritoryHistory!!!!!\n{'BusinessEntityID': 0, 'TerritoryID': 0, 'StartDate': 0, 'EndDate': 13, 'rowguid': 0, 'ModifiedDate': 0}\n\nThe  table is  : df_ShoppingCartItem\nThe count of df: 3\n<<OK>> No nulls found in df_ShoppingCartItem <<OK>>\n\nThe  table is  : df_SpecialOffer\nThe count of df: 16\n!!!!! Null values detected in df_SpecialOffer!!!!!\n{'SpecialOfferID': 0, 'Description': 0, 'DiscountPct': 0, 'Type': 0, 'Category': 0, 'StartDate': 0, 'EndDate': 0, 'MinQty': 0, 'MaxQty': 12, 'rowguid': 0, 'ModifiedDate': 0}\n\nThe  table is  : df_SpecialOfferProduct\nThe count of df: 538\n<<OK>> No nulls found in df_SpecialOfferProduct <<OK>>\n\nThe  table is  : df_Store\nThe count of df: 701\n<<OK>> No nulls found in df_Store <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8903882494457152>, line 5\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m file_name\u001B[38;5;241m=\u001B[39mtable\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
       "\u001B[1;32m      4\u001B[0m file_df\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdf_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mfile_name\n",
       "\u001B[0;32m----> 5\u001B[0m file_path \u001B[38;5;241m=\u001B[39m base_path\u001B[38;5;241m+\u001B[39mtable\u001B[38;5;241m+\u001B[39mfile_name\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      6\u001B[0m df[file_df]\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mparquet(file_path,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe name of the dataframe is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_df\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and count is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[file_df]\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'base_path' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'base_path' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8903882494457152>, line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m file_name\u001B[38;5;241m=\u001B[39mtable\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      4\u001B[0m file_df\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdf_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mfile_name\n\u001B[0;32m----> 5\u001B[0m file_path \u001B[38;5;241m=\u001B[39m base_path\u001B[38;5;241m+\u001B[39mtable\u001B[38;5;241m+\u001B[39mfile_name\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m df[file_df]\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mparquet(file_path,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe name of the dataframe is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_df\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and count is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf[file_df]\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
        "\u001B[0;31mNameError\u001B[0m: name 'base_path' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the count and validating the null values in each of the dataframes. \n",
    "for table in df.keys():\n",
    "    print(\"\\nThe  table is  :\", table)\n",
    "    print(\"The count of df:\",df[table].count())\n",
    "    check_nulls(df[table],table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19738541-43cc-4ce4-ae10-df926ef50100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "So from the above cell, it is clear that most of the dataframes are without null values, however below have null values. Lets review them if data needs imputed. \n",
    "\n",
    "- df_Customer\n",
    "- df_SalesOrderDetail\n",
    "- df_SalesOrderHeader \n",
    "- df_SalesPerson \n",
    "- df_SalesTerritoryHistory \n",
    "- df_SpecialOffer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02200845-fcf0-4923-a5ab-155f88be91e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original table is  :\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\n|CustomerID|PersonID|StoreID|TerritoryID|AccountNumber|             rowguid|        ModifiedDate|\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\n|         1|    NULL|    934|          1|   AW00000001|3f5ae95e-b87d-4ae...|2014-09-12 11:15:...|\n|         2|    NULL|   1028|          1|   AW00000002|e552f657-a9af-4a7...|2014-09-12 11:15:...|\n|         3|    NULL|    642|          4|   AW00000003|130774b1-db21-4ef...|2014-09-12 11:15:...|\n|         4|    NULL|    932|          4|   AW00000004|ff862851-1daa-404...|2014-09-12 11:15:...|\n|         5|    NULL|   1026|          4|   AW00000005|83905bdc-6f5e-4f7...|2014-09-12 11:15:...|\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\nonly showing top 5 rows\n\nThe Updated table is  :\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\n|CustomerID|PersonID|StoreID|TerritoryID|AccountNumber|             rowguid|        ModifiedDate|\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\n|         1|       0|    934|          1|   AW00000001|3f5ae95e-b87d-4ae...|2014-09-12 11:15:...|\n|         2|       0|   1028|          1|   AW00000002|e552f657-a9af-4a7...|2014-09-12 11:15:...|\n|         3|       0|    642|          4|   AW00000003|130774b1-db21-4ef...|2014-09-12 11:15:...|\n|         4|       0|    932|          4|   AW00000004|ff862851-1daa-404...|2014-09-12 11:15:...|\n|         5|       0|   1026|          4|   AW00000005|83905bdc-6f5e-4f7...|2014-09-12 11:15:...|\n+----------+--------+-------+-----------+-------------+--------------------+--------------------+\nonly showing top 5 rows\n\n<<OK>> No nulls found in df_Customer <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3271532783269673>, line 9\u001B[0m\n",
       "\u001B[1;32m      6\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m2500\u001B[39m)\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Update EndDate where it's NULL as 2 monthsr from the StartDate. \u001B[39;00m\n",
       "\u001B[0;32m----> 9\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEndDate\u001B[39m\u001B[38;5;124m\"\u001B[39m, when(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEndDate\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39misNull(), add_months(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStartDate\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;241m2\u001B[39m))\u001B[38;5;241m.\u001B[39motherwise(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEndDate\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Update ProductAssemblyID where its null as 0 . \u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProductAssemblyID\u001B[39m\u001B[38;5;124m\"\u001B[39m, when(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProductAssemblyID\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39misNull(), \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39motherwise(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProductAssemblyID\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:6282\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n",
       "\u001B[1;32m   6277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n",
       "\u001B[1;32m   6278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m   6279\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   6280\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n",
       "\u001B[1;32m   6281\u001B[0m     )\n",
       "\u001B[0;32m-> 6282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mwithColumn(colName, col\u001B[38;5;241m.\u001B[39m_jc), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `EndDate` cannot be resolved. Did you mean one of the following? [`ModifiedDate`, `StoreID`, `rowguid`, `PersonID`, `CustomerID`]. SQLSTATE: 42703;\n",
       "'Project [CustomerID#167, PersonID#168, StoreID#169, TerritoryID#170, AccountNumber#171, rowguid#172, ModifiedDate#173, CASE WHEN 'isNull('EndDate) THEN 'add_months('StartDate, 2) ELSE 'EndDate END AS EndDate#2455]\n",
       "+- Relation [CustomerID#167,PersonID#168,StoreID#169,TerritoryID#170,AccountNumber#171,rowguid#172,ModifiedDate#173] parquet\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `EndDate` cannot be resolved. Did you mean one of the following? [`ModifiedDate`, `StoreID`, `rowguid`, `PersonID`, `CustomerID`]. SQLSTATE: 42703;\n'Project [CustomerID#167, PersonID#168, StoreID#169, TerritoryID#170, AccountNumber#171, rowguid#172, ModifiedDate#173, CASE WHEN 'isNull('EndDate) THEN 'add_months('StartDate, 2) ELSE 'EndDate END AS EndDate#2455]\n+- Relation [CustomerID#167,PersonID#168,StoreID#169,TerritoryID#170,AccountNumber#171,rowguid#172,ModifiedDate#173] parquet\n"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_COLUMN.WITH_SUGGESTION",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "42703",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-3271532783269673>, line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m2500\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Update EndDate where it's NULL as 2 monthsr from the StartDate. \u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEndDate\u001B[39m\u001B[38;5;124m\"\u001B[39m, when(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEndDate\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39misNull(), add_months(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStartDate\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;241m2\u001B[39m))\u001B[38;5;241m.\u001B[39motherwise(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEndDate\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Update ProductAssemblyID where its null as 0 . \u001B[39;00m\n\u001B[1;32m     11\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_Customer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProductAssemblyID\u001B[39m\u001B[38;5;124m\"\u001B[39m, when(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProductAssemblyID\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39misNull(), \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39motherwise(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProductAssemblyID\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:6282\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n\u001B[1;32m   6277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n\u001B[1;32m   6278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   6279\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   6280\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   6281\u001B[0m     )\n\u001B[0;32m-> 6282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mwithColumn(colName, col\u001B[38;5;241m.\u001B[39m_jc), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `EndDate` cannot be resolved. Did you mean one of the following? [`ModifiedDate`, `StoreID`, `rowguid`, `PersonID`, `CustomerID`]. SQLSTATE: 42703;\n'Project [CustomerID#167, PersonID#168, StoreID#169, TerritoryID#170, AccountNumber#171, rowguid#172, ModifiedDate#173, CASE WHEN 'isNull('EndDate) THEN 'add_months('StartDate, 2) ELSE 'EndDate END AS EndDate#2455]\n+- Relation [CustomerID#167,PersonID#168,StoreID#169,TerritoryID#170,AccountNumber#171,rowguid#172,ModifiedDate#173] parquet\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixing null in the table df_Customer\n",
    "\n",
    "# display Original dataframe\n",
    "print(\"The Original table is  :\")\n",
    "df['df_Customer'].show(5)\n",
    "\n",
    "# Update StoreID where its null as 0. \n",
    "df['df_Customer'] = df['df_Customer'].withColumn(\"StoreID\", when(col(\"StoreID\").isNull(), 0).otherwise(col(\"StoreID\")))\n",
    "# Update PersonID where its null as 0 . \n",
    "df['df_Customer'] = df['df_Customer'].withColumn(\"PersonID\", when(col(\"PersonID\").isNull(), 0).otherwise(col(\"PersonID\")))\n",
    "\n",
    "# Show updated DataFrame\n",
    "print(\"The Updated table is  :\")\n",
    "df['df_Customer'].show(5)\n",
    "\n",
    "# Validating the null values\n",
    "check_nulls(df['df_Customer'], 'df_Customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6011a778-90ff-4359-888a-13fc14a561fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original table is  :\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\n|SalesOrderID|SalesOrderDetailID|CarrierTrackingNumber|OrderQty|ProductID|SpecialOfferID|UnitPrice|UnitPriceDiscount|  LineTotal|             rowguid|       ModifiedDate|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\n|       43659|                 1|         4911-403C-98|       1|      776|             1|2024.9940|           0.0000|2024.994000|b207c96d-d9e6-402...|2011-05-31 00:00:00|\n|       43659|                 2|         4911-403C-98|       3|      777|             1|2024.9940|           0.0000|6074.982000|7abb600d-1e77-41b...|2011-05-31 00:00:00|\n|       43659|                 3|         4911-403C-98|       1|      778|             1|2024.9940|           0.0000|2024.994000|475cf8c6-49f6-486...|2011-05-31 00:00:00|\n|       43659|                 4|         4911-403C-98|       1|      771|             1|2039.9940|           0.0000|2039.994000|04c4de91-5815-45d...|2011-05-31 00:00:00|\n|       43659|                 5|         4911-403C-98|       1|      772|             1|2039.9940|           0.0000|2039.994000|5a74c7d2-e641-438...|2011-05-31 00:00:00|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\nonly showing top 5 rows\n\nThe Updated table is  :\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\n|SalesOrderID|SalesOrderDetailID|CarrierTrackingNumber|OrderQty|ProductID|SpecialOfferID|UnitPrice|UnitPriceDiscount|  LineTotal|             rowguid|       ModifiedDate|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\n|       43659|                 1|         4911-403C-98|       1|      776|             1|2024.9940|           0.0000|2024.994000|b207c96d-d9e6-402...|2011-05-31 00:00:00|\n|       43659|                 2|         4911-403C-98|       3|      777|             1|2024.9940|           0.0000|6074.982000|7abb600d-1e77-41b...|2011-05-31 00:00:00|\n|       43659|                 3|         4911-403C-98|       1|      778|             1|2024.9940|           0.0000|2024.994000|475cf8c6-49f6-486...|2011-05-31 00:00:00|\n|       43659|                 4|         4911-403C-98|       1|      771|             1|2039.9940|           0.0000|2039.994000|04c4de91-5815-45d...|2011-05-31 00:00:00|\n|       43659|                 5|         4911-403C-98|       1|      772|             1|2039.9940|           0.0000|2039.994000|5a74c7d2-e641-438...|2011-05-31 00:00:00|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+-------------------+\nonly showing top 5 rows\n\n<<OK>> No nulls found in df_SalesOrderDetail <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixing null in the table df_SalesOrderDetail\n",
    "\n",
    "from pyspark.sql.functions import col, when, add_months\n",
    "\n",
    "# display Original dataframe\n",
    "print(\"The Original table is  :\")\n",
    "df['df_SalesOrderDetail'].show(5)\n",
    "\n",
    "# Update StoreID where its null as \"not Available\". \n",
    "df['df_SalesOrderDetail'] = df['df_SalesOrderDetail'].withColumn(\"CarrierTrackingNumber\", when(col(\"CarrierTrackingNumber\").isNull(), \"Not Available\").otherwise(col(\"CarrierTrackingNumber\")))\n",
    "\n",
    "# Show updated DataFrame\n",
    "print(\"The Updated table is  :\")\n",
    "df['df_SalesOrderDetail'].show(5)\n",
    "\n",
    "# Validating the null values\n",
    "check_nulls(df['df_SalesOrderDetail'], 'df_SalesOrderDetail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03223ad-b6c4-4b7d-b93e-553fd54c3a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original table is  :\nThe Updated table is  :\n<<OK>> No nulls found in df_SalesOrderHeader <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;36m  File \u001B[0;32m<command-3271532783269675>, line 32\u001B[0;36m\u001B[0m\n",
       "\u001B[0;31m    check_nulls(df['df_SalesOrderHeader'], 'df_SalesOrderHeader')'''\u001B[0m\n",
       "\u001B[0m                                                                 ^\u001B[0m\n",
       "\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "SyntaxError",
        "evalue": "incomplete input (command-3271532783269675-588793400, line 32)"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;36m  File \u001B[0;32m<command-3271532783269675>, line 32\u001B[0;36m\u001B[0m\n\u001B[0;31m    check_nulls(df['df_SalesOrderHeader'], 'df_SalesOrderHeader')'''\u001B[0m\n\u001B[0m                                                                 ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixing null in the table df_SalesOrderHeader\n",
    "\n",
    "# Show original DataFrame\n",
    "print(\"The Original table is  :\")\n",
    "#df['df_SalesOrderHeader'].show(5)\n",
    "\n",
    "# Update \"SalesPersonID\" as 0 for null values\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].withColumn(\"SalesPersonID\", when((col(\"SalesPersonID\").isNull()), 0).otherwise(col(\"SalesPersonID\")))\n",
    "\n",
    "# Update \"PurchaseOrderNumber\" as 0 for null values\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].withColumn(\"PurchaseOrderNumber\", when((col(\"PurchaseOrderNumber\").isNull()), 0).otherwise(col(\"PurchaseOrderNumber\")))\n",
    "\n",
    "# dropping comment column as all values are null\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].drop('Comment')\n",
    "\n",
    "# Update \"CurrencyRateID\" as 0 where it's NULL\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].withColumn(\"CurrencyRateID\", when(col(\"CurrencyRateID\").isNull(), 0).otherwise(col(\"CurrencyRateID\")))\n",
    "\n",
    "# Update \"CreditCardID\" as 0 where it's NULL\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].withColumn(\"CreditCardID\", when(col(\"CreditCardID\").isNull(), 0).otherwise(col(\"CreditCardID\")))\n",
    "\n",
    "# Update \"CreditCardApprovalCode\" as 0 where it's NULL\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].withColumn(\"CreditCardApprovalCode\", when(col(\"CreditCardApprovalCode\").isNull(), \"Not Available\").otherwise(col(\"CreditCardApprovalCode\")))\n",
    "\n",
    "# Update \"CurrencyRateID\" as 0 where it's NULL\n",
    "df['df_SalesOrderHeader'] = df['df_SalesOrderHeader'].withColumn(\"CurrencyRateID\", when(col(\"CurrencyRateID\").isNull(), 0).otherwise(col(\"CurrencyRateID\")))\n",
    "\n",
    "# Show Updated DataFrame\n",
    "print(\"The Updated table is  :\")\n",
    "#df['df_SalesOrderHeader'].show(5)\n",
    "\n",
    "check_nulls(df['df_SalesOrderHeader'], 'df_SalesOrderHeader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f1d053-9e13-47f0-9b30-bab00f656221",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original table is  :\n+----------------+-----------+-----------+---------+-------------+------------+-------------+--------------------+-------------------+\n|BusinessEntityID|TerritoryID| SalesQuota|    Bonus|CommissionPct|    SalesYTD|SalesLastYear|             rowguid|       ModifiedDate|\n+----------------+-----------+-----------+---------+-------------+------------+-------------+--------------------+-------------------+\n|             274|       NULL|       NULL|   0.0000|       0.0000| 559697.5639|       0.0000|48754992-9ee0-4c0...|2010-12-28 00:00:00|\n|             275|          2|300000.0000|4100.0000|       0.0120|3763178.1787| 1750406.4785|1e0a7274-3064-4f5...|2011-05-24 00:00:00|\n|             276|          4|250000.0000|2000.0000|       0.0150|4251368.5497| 1439156.0291|4dd9eee4-8e81-4f8...|2011-05-24 00:00:00|\n|             277|          3|250000.0000|2500.0000|       0.0150|3189418.3662| 1997186.2037|39012928-bfec-424...|2011-05-24 00:00:00|\n|             278|          6|250000.0000| 500.0000|       0.0100|1453719.4653| 1620276.8966|7a0ae1ab-b283-40f...|2011-05-24 00:00:00|\n+----------------+-----------+-----------+---------+-------------+------------+-------------+--------------------+-------------------+\nonly showing top 5 rows\n\nThe Updated table is  :\n+----------------+-----------+---------------+---------+-------------+------------+-------------+--------------------+-------------------+\n|BusinessEntityID|TerritoryID|     SalesQuota|    Bonus|CommissionPct|    SalesYTD|SalesLastYear|             rowguid|       ModifiedDate|\n+----------------+-----------+---------------+---------+-------------+------------+-------------+--------------------+-------------------+\n|             274|          0|260714.28571429|   0.0000|       0.0000| 559697.5639|       0.0000|48754992-9ee0-4c0...|2010-12-28 00:00:00|\n|             275|          2|300000.00000000|4100.0000|       0.0120|3763178.1787| 1750406.4785|1e0a7274-3064-4f5...|2011-05-24 00:00:00|\n|             276|          4|250000.00000000|2000.0000|       0.0150|4251368.5497| 1439156.0291|4dd9eee4-8e81-4f8...|2011-05-24 00:00:00|\n|             277|          3|250000.00000000|2500.0000|       0.0150|3189418.3662| 1997186.2037|39012928-bfec-424...|2011-05-24 00:00:00|\n|             278|          6|250000.00000000| 500.0000|       0.0100|1453719.4653| 1620276.8966|7a0ae1ab-b283-40f...|2011-05-24 00:00:00|\n+----------------+-----------+---------------+---------+-------------+------------+-------------+--------------------+-------------------+\nonly showing top 5 rows\n\n<<OK>> No nulls found in df_SalesPerson <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixing null in the table df_SalesPerson\n",
    " \n",
    "# Show Original DataFrame\n",
    "print(\"The Original table is  :\")\n",
    "df['df_SalesPerson'].show(5)\n",
    "\n",
    "avg_SalesQuota=df['df_SalesPerson'].select('SalesQuota').agg({'SalesQuota':'avg'}).collect()[0][0]\n",
    "\n",
    "df['df_SalesPerson']=df['df_SalesPerson'].withColumn(\"SalesQuota\",when(col(\"SalesQuota\").isNull(),avg_SalesQuota).otherwise(col(\"SalesQuota\")))\n",
    "df['df_SalesPerson']=df['df_SalesPerson'].withColumn(\"TerritoryID\",when(col(\"TerritoryID\").isNull(),0).otherwise(col(\"TerritoryID\")))\n",
    "\n",
    "# Show Updated DataFrame\n",
    "print(\"The Updated table is  :\")\n",
    "df['df_SalesPerson'].show(5)\n",
    "check_nulls(df['df_SalesPerson'],'df_SalesPerson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cfb162b-f054-49ab-9928-a209b9168c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original table is  :\n+----------------+-----------+-------------------+-------------------+--------------------+-------------------+\n|BusinessEntityID|TerritoryID|          StartDate|            EndDate|             rowguid|       ModifiedDate|\n+----------------+-----------+-------------------+-------------------+--------------------+-------------------+\n|             275|          2|2011-05-31 00:00:00|2012-11-29 00:00:00|8563ce6a-00ff-47d...|2012-11-22 00:00:00|\n|             275|          3|2012-11-30 00:00:00|               NULL|2f44304c-ee87-4c7...|2012-11-23 00:00:00|\n|             276|          4|2011-05-31 00:00:00|               NULL|64bcb1b3-a793-40b...|2011-05-24 00:00:00|\n|             277|          3|2011-05-31 00:00:00|2012-11-29 00:00:00|3e9f893d-5142-46c...|2012-11-22 00:00:00|\n|             277|          2|2012-11-30 00:00:00|               NULL|132e4721-32dd-4a7...|2012-11-23 00:00:00|\n+----------------+-----------+-------------------+-------------------+--------------------+-------------------+\nonly showing top 5 rows\n\nThe Updated table is  :\n+----------------+-----------+-------------------+-------------------+--------------------+-------------------+\n|BusinessEntityID|TerritoryID|          StartDate|            EndDate|             rowguid|       ModifiedDate|\n+----------------+-----------+-------------------+-------------------+--------------------+-------------------+\n|             275|          2|2011-05-31 00:00:00|2012-11-29 00:00:00|8563ce6a-00ff-47d...|2012-11-22 00:00:00|\n|             275|          3|2012-11-30 00:00:00|2013-11-30 00:00:00|2f44304c-ee87-4c7...|2012-11-23 00:00:00|\n|             276|          4|2011-05-31 00:00:00|2012-05-30 00:00:00|64bcb1b3-a793-40b...|2011-05-24 00:00:00|\n|             277|          3|2011-05-31 00:00:00|2012-11-29 00:00:00|3e9f893d-5142-46c...|2012-11-22 00:00:00|\n|             277|          2|2012-11-30 00:00:00|2013-11-30 00:00:00|132e4721-32dd-4a7...|2012-11-23 00:00:00|\n+----------------+-----------+-------------------+-------------------+--------------------+-------------------+\nonly showing top 5 rows\n\n<<OK>> No nulls found in df_SalesTerritoryHistory <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixing null in the table df_SalesTerritoryHistory\n",
    "from pyspark.sql.functions import date_add, col\n",
    "\n",
    "# Show Original DataFrame\n",
    "print(\"The Original table is  :\")\n",
    "df['df_SalesTerritoryHistory'].show(5)\n",
    "\n",
    "df['df_SalesTerritoryHistory']=df['df_SalesTerritoryHistory'].withColumn(\"EndDate\",when(col(\"EndDate\").isNull(),date_add(col(\"StartDate\"),365)).otherwise(col(\"EndDate\")))\n",
    "\n",
    "# Show Updated DataFrame\n",
    "print(\"The Updated table is  :\")\n",
    "df['df_SalesTerritoryHistory'].show(5)\n",
    "\n",
    "check_nulls(df['df_SalesTerritoryHistory'],'df_SalesTerritoryHistory')                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "568349b9-e938-4f9e-b93d-5ad323428be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original table is  :\n+--------------+--------------------+-----------+---------------+-----------+-------------------+-------------------+------+------+--------------------+-------------------+\n|SpecialOfferID|         Description|DiscountPct|           Type|   Category|          StartDate|            EndDate|MinQty|MaxQty|             rowguid|       ModifiedDate|\n+--------------+--------------------+-----------+---------------+-----------+-------------------+-------------------+------+------+--------------------+-------------------+\n|             1|         No Discount|     0.0000|    No Discount|No Discount|2011-05-01 00:00:00|2014-11-30 00:00:00|     0|  NULL|0290c4f5-191f-433...|2011-04-01 00:00:00|\n|             2|Volume Discount 1...|     0.0200|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    11|    14|d7542ee7-15db-454...|2011-05-01 00:00:00|\n|             3|Volume Discount 1...|     0.0500|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    15|    24|4bdbcc01-8cf7-40a...|2011-05-01 00:00:00|\n|             4|Volume Discount 2...|     0.1000|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    25|    40|504b5e85-8f3f-4eb...|2011-05-01 00:00:00|\n|             5|Volume Discount 4...|     0.1500|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    41|    60|677e1d9d-944f-4e8...|2011-05-01 00:00:00|\n|             6|Volume Discount o...|     0.2000|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    61|  NULL|8157f569-4e8d-46b...|2011-05-01 00:00:00|\n+--------------+--------------------+-----------+---------------+-----------+-------------------+-------------------+------+------+--------------------+-------------------+\nonly showing top 6 rows\n\nThe Updated table is  :\n+--------------+--------------------+-----------+---------------+-----------+-------------------+-------------------+------+------+--------------------+-------------------+\n|SpecialOfferID|         Description|DiscountPct|           Type|   Category|          StartDate|            EndDate|MinQty|MaxQty|             rowguid|       ModifiedDate|\n+--------------+--------------------+-----------+---------------+-----------+-------------------+-------------------+------+------+--------------------+-------------------+\n|             1|         No Discount|     0.0000|    No Discount|No Discount|2011-05-01 00:00:00|2014-11-30 00:00:00|     0|     0|0290c4f5-191f-433...|2011-04-01 00:00:00|\n|             2|Volume Discount 1...|     0.0200|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    11|    14|d7542ee7-15db-454...|2011-05-01 00:00:00|\n|             3|Volume Discount 1...|     0.0500|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    15|    24|4bdbcc01-8cf7-40a...|2011-05-01 00:00:00|\n|             4|Volume Discount 2...|     0.1000|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    25|    40|504b5e85-8f3f-4eb...|2011-05-01 00:00:00|\n|             5|Volume Discount 4...|     0.1500|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    41|    60|677e1d9d-944f-4e8...|2011-05-01 00:00:00|\n|             6|Volume Discount o...|     0.2000|Volume Discount|   Reseller|2011-05-31 00:00:00|2014-05-30 00:00:00|    61|    64|8157f569-4e8d-46b...|2011-05-01 00:00:00|\n+--------------+--------------------+-----------+---------------+-----------+-------------------+-------------------+------+------+--------------------+-------------------+\nonly showing top 6 rows\n\n<<OK>> No nulls found in df_SpecialOffer <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixing null in the table df_SpecialOffer\n",
    "from pyspark.sql.functions import col, when, lit, coalesce\n",
    "\n",
    "# Show Original DataFrame\n",
    "print(\"The Original table is  :\")\n",
    "df['df_SpecialOffer'].show(6)\n",
    "\n",
    "# Updating the MaxQty as 0 where it's null and MinQty is 0\n",
    "df['df_SpecialOffer']=df['df_SpecialOffer'].withColumn(\"MaxQty\",when(col(\"MaxQty\").isNull() & (col(\"MinQty\") == 0), 0).otherwise(col(\"MaxQty\")))\n",
    "\n",
    "# Collect MaxQty and MinQty values as lists\n",
    "MaxQty_list = [row['MaxQty'] for row in df['df_SpecialOffer'].select('MaxQty').collect()]\n",
    "MinQty_list = [row['MinQty'] for row in df['df_SpecialOffer'].select('MinQty').collect()]\n",
    "\n",
    "#Calculate the average of difference of MaxQty and MinQty\n",
    "avg_qty = [a - b for a, b in zip(MaxQty_list, MinQty_list) if a is not None and b is not None]\n",
    "avg_qty_to_update=round((sum(avg_qty) / len(avg_qty) if avg_qty else 0),)\n",
    "\n",
    "#Impute the MaxQty value as MinQty + Avg_qty that is calcualted. \n",
    "df['df_SpecialOffer']=df['df_SpecialOffer'].withColumn(\"MaxQty\",when(col(\"MaxQty\").isNull(), ((col(\"MinQty\")) + lit(avg_qty_to_update)))\n",
    "    .otherwise(col(\"MaxQty\")))\n",
    "\n",
    "# Show Updated DataFrame\n",
    "print(\"The Updated table is  :\")\n",
    "df['df_SpecialOffer'].show(6)\n",
    "\n",
    "check_nulls(df['df_SpecialOffer'],'df_SpecialOffer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fee237-8751-4abf-be66-7b1b6aba4e5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe  table is  : df_CountryRegionCurrency\nThe count of df: 109\n<<OK>> No nulls found in df_CountryRegionCurrency <<OK>>\n\nThe  table is  : df_CreditCard\nThe count of df: 19118\n<<OK>> No nulls found in df_CreditCard <<OK>>\n\nThe  table is  : df_Currency\nThe count of df: 105\n<<OK>> No nulls found in df_Currency <<OK>>\n\nThe  table is  : df_CurrencyRate\nThe count of df: 13532\n<<OK>> No nulls found in df_CurrencyRate <<OK>>\n\nThe  table is  : df_Customer\nThe count of df: 19820\n<<OK>> No nulls found in df_Customer <<OK>>\n\nThe  table is  : df_PersonCreditCard\nThe count of df: 19118\n<<OK>> No nulls found in df_PersonCreditCard <<OK>>\n\nThe  table is  : df_SalesOrderDetail\nThe count of df: 121317\n<<OK>> No nulls found in df_SalesOrderDetail <<OK>>\n\nThe  table is  : df_SalesOrderHeader\nThe count of df: 31465\n<<OK>> No nulls found in df_SalesOrderHeader <<OK>>\n\nThe  table is  : df_SalesOrderHeaderSalesReason\nThe count of df: 27647\n<<OK>> No nulls found in df_SalesOrderHeaderSalesReason <<OK>>\n\nThe  table is  : df_SalesPerson\nThe count of df: 17\n<<OK>> No nulls found in df_SalesPerson <<OK>>\n\nThe  table is  : df_SalesPersonQuotaHistory\nThe count of df: 163\n<<OK>> No nulls found in df_SalesPersonQuotaHistory <<OK>>\n\nThe  table is  : df_SalesReason\nThe count of df: 10\n<<OK>> No nulls found in df_SalesReason <<OK>>\n\nThe  table is  : df_SalesTaxRate\nThe count of df: 29\n<<OK>> No nulls found in df_SalesTaxRate <<OK>>\n\nThe  table is  : df_SalesTerritory\nThe count of df: 10\n<<OK>> No nulls found in df_SalesTerritory <<OK>>\n\nThe  table is  : df_SalesTerritoryHistory\nThe count of df: 17\n<<OK>> No nulls found in df_SalesTerritoryHistory <<OK>>\n\nThe  table is  : df_ShoppingCartItem\nThe count of df: 3\n<<OK>> No nulls found in df_ShoppingCartItem <<OK>>\n\nThe  table is  : df_SpecialOffer\nThe count of df: 16\n<<OK>> No nulls found in df_SpecialOffer <<OK>>\n\nThe  table is  : df_SpecialOfferProduct\nThe count of df: 538\n<<OK>> No nulls found in df_SpecialOfferProduct <<OK>>\n\nThe  table is  : df_Store\nThe count of df: 701\n<<OK>> No nulls found in df_Store <<OK>>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-validate if nulls are handled in all the tables. \n",
    "for table in df.keys():\n",
    "    print(\"\\nThe  table is  :\", table)\n",
    "    print(\"The count of df:\",df[table].count())\n",
    "    check_nulls(df[table],table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c942a2d-31d7-4d7f-8598-0bb34fe4be8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "View table schema and then transform Timestamp datatype to Date in all tables since the time values in timestamp are zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "352e266f-e655-4834-bcdb-857262bbb9f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the function to print the Schema. \n",
    "def print_schema(df, df_name):\n",
    "    print(\"\\nThe Schema of the table {} is :\".format(df_name))\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a687242d-058e-4718-8637-7c2fc5ff9b39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe Schema of the table df_CountryRegionCurrency is :\nroot\n |-- CountryRegionCode: string (nullable = true)\n |-- CurrencyCode: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_CreditCard is :\nroot\n |-- CreditCardID: integer (nullable = true)\n |-- CardType: string (nullable = true)\n |-- CardNumber: string (nullable = true)\n |-- ExpMonth: integer (nullable = true)\n |-- ExpYear: integer (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_Currency is :\nroot\n |-- CurrencyCode: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_CurrencyRate is :\nroot\n |-- CurrencyRateID: integer (nullable = true)\n |-- CurrencyRateDate: timestamp (nullable = true)\n |-- FromCurrencyCode: string (nullable = true)\n |-- ToCurrencyCode: string (nullable = true)\n |-- AverageRate: decimal(19,4) (nullable = true)\n |-- EndOfDayRate: decimal(19,4) (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_Customer is :\nroot\n |-- CustomerID: integer (nullable = true)\n |-- PersonID: integer (nullable = true)\n |-- StoreID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- AccountNumber: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_PersonCreditCard is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- CreditCardID: integer (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesOrderDetail is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- SalesOrderDetailID: integer (nullable = true)\n |-- CarrierTrackingNumber: string (nullable = true)\n |-- OrderQty: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- SpecialOfferID: integer (nullable = true)\n |-- UnitPrice: decimal(19,4) (nullable = true)\n |-- UnitPriceDiscount: decimal(19,4) (nullable = true)\n |-- LineTotal: decimal(38,6) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesOrderHeader is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- RevisionNumber: integer (nullable = true)\n |-- OrderDate: timestamp (nullable = true)\n |-- DueDate: timestamp (nullable = true)\n |-- ShipDate: timestamp (nullable = true)\n |-- Status: integer (nullable = true)\n |-- OnlineOrderFlag: boolean (nullable = true)\n |-- SalesOrderNumber: string (nullable = true)\n |-- PurchaseOrderNumber: string (nullable = true)\n |-- AccountNumber: string (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- SalesPersonID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- BillToAddressID: integer (nullable = true)\n |-- ShipToAddressID: integer (nullable = true)\n |-- ShipMethodID: integer (nullable = true)\n |-- CreditCardID: integer (nullable = true)\n |-- CreditCardApprovalCode: string (nullable = true)\n |-- CurrencyRateID: integer (nullable = true)\n |-- SubTotal: decimal(19,4) (nullable = true)\n |-- TaxAmt: decimal(19,4) (nullable = true)\n |-- Freight: decimal(19,4) (nullable = true)\n |-- TotalDue: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesOrderHeaderSalesReason is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- SalesReasonID: integer (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesPerson is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- SalesQuota: decimal(23,8) (nullable = true)\n |-- Bonus: decimal(19,4) (nullable = true)\n |-- CommissionPct: decimal(10,4) (nullable = true)\n |-- SalesYTD: decimal(19,4) (nullable = true)\n |-- SalesLastYear: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesPersonQuotaHistory is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- QuotaDate: timestamp (nullable = true)\n |-- SalesQuota: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesReason is :\nroot\n |-- SalesReasonID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- ReasonType: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesTaxRate is :\nroot\n |-- SalesTaxRateID: integer (nullable = true)\n |-- StateProvinceID: integer (nullable = true)\n |-- TaxType: integer (nullable = true)\n |-- TaxRate: decimal(10,4) (nullable = true)\n |-- Name: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesTerritory is :\nroot\n |-- TerritoryID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- CountryRegionCode: string (nullable = true)\n |-- Group: string (nullable = true)\n |-- SalesYTD: decimal(19,4) (nullable = true)\n |-- SalesLastYear: decimal(19,4) (nullable = true)\n |-- CostYTD: decimal(19,4) (nullable = true)\n |-- CostLastYear: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SalesTerritoryHistory is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- StartDate: timestamp (nullable = true)\n |-- EndDate: timestamp (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_ShoppingCartItem is :\nroot\n |-- ShoppingCartItemID: integer (nullable = true)\n |-- ShoppingCartID: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- DateCreated: timestamp (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SpecialOffer is :\nroot\n |-- SpecialOfferID: integer (nullable = true)\n |-- Description: string (nullable = true)\n |-- DiscountPct: decimal(10,4) (nullable = true)\n |-- Type: string (nullable = true)\n |-- Category: string (nullable = true)\n |-- StartDate: timestamp (nullable = true)\n |-- EndDate: timestamp (nullable = true)\n |-- MinQty: integer (nullable = true)\n |-- MaxQty: integer (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_SpecialOfferProduct is :\nroot\n |-- SpecialOfferID: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\nThe Schema of the table df_Store is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- SalesPersonID: integer (nullable = true)\n |-- Demographics: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the schema of each tables to identify the timestamp column\n",
    "for file in df.keys():\n",
    "    print_schema(df[file],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43337350-e57f-43e1-a367-90259114835d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n df_CountryRegionCurrency  in Original Schema\n\nThe Schema of the table df_CountryRegionCurrency is :\nroot\n |-- CountryRegionCode: string (nullable = true)\n |-- CurrencyCode: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_CountryRegionCurrency  in transformed Schema\n\nThe Schema of the table df_CountryRegionCurrency is :\nroot\n |-- CountryRegionCode: string (nullable = true)\n |-- CurrencyCode: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_CreditCard  in Original Schema\n\nThe Schema of the table df_CreditCard is :\nroot\n |-- CreditCardID: integer (nullable = true)\n |-- CardType: string (nullable = true)\n |-- CardNumber: string (nullable = true)\n |-- ExpMonth: integer (nullable = true)\n |-- ExpYear: integer (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_CreditCard  in transformed Schema\n\nThe Schema of the table df_CreditCard is :\nroot\n |-- CreditCardID: integer (nullable = true)\n |-- CardType: string (nullable = true)\n |-- CardNumber: string (nullable = true)\n |-- ExpMonth: integer (nullable = true)\n |-- ExpYear: integer (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_Currency  in Original Schema\n\nThe Schema of the table df_Currency is :\nroot\n |-- CurrencyCode: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_Currency  in transformed Schema\n\nThe Schema of the table df_Currency is :\nroot\n |-- CurrencyCode: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_CurrencyRate  in Original Schema\n\nThe Schema of the table df_CurrencyRate is :\nroot\n |-- CurrencyRateID: integer (nullable = true)\n |-- CurrencyRateDate: timestamp (nullable = true)\n |-- FromCurrencyCode: string (nullable = true)\n |-- ToCurrencyCode: string (nullable = true)\n |-- AverageRate: decimal(19,4) (nullable = true)\n |-- EndOfDayRate: decimal(19,4) (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_CurrencyRate  in transformed Schema\n\nThe Schema of the table df_CurrencyRate is :\nroot\n |-- CurrencyRateID: integer (nullable = true)\n |-- CurrencyRateDate: date (nullable = true)\n |-- FromCurrencyCode: string (nullable = true)\n |-- ToCurrencyCode: string (nullable = true)\n |-- AverageRate: decimal(19,4) (nullable = true)\n |-- EndOfDayRate: decimal(19,4) (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_Customer  in Original Schema\n\nThe Schema of the table df_Customer is :\nroot\n |-- CustomerID: integer (nullable = true)\n |-- PersonID: integer (nullable = true)\n |-- StoreID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- AccountNumber: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_Customer  in transformed Schema\n\nThe Schema of the table df_Customer is :\nroot\n |-- CustomerID: integer (nullable = true)\n |-- PersonID: integer (nullable = true)\n |-- StoreID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- AccountNumber: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_PersonCreditCard  in Original Schema\n\nThe Schema of the table df_PersonCreditCard is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- CreditCardID: integer (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_PersonCreditCard  in transformed Schema\n\nThe Schema of the table df_PersonCreditCard is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- CreditCardID: integer (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesOrderDetail  in Original Schema\n\nThe Schema of the table df_SalesOrderDetail is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- SalesOrderDetailID: integer (nullable = true)\n |-- CarrierTrackingNumber: string (nullable = true)\n |-- OrderQty: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- SpecialOfferID: integer (nullable = true)\n |-- UnitPrice: decimal(19,4) (nullable = true)\n |-- UnitPriceDiscount: decimal(19,4) (nullable = true)\n |-- LineTotal: decimal(38,6) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesOrderDetail  in transformed Schema\n\nThe Schema of the table df_SalesOrderDetail is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- SalesOrderDetailID: integer (nullable = true)\n |-- CarrierTrackingNumber: string (nullable = true)\n |-- OrderQty: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- SpecialOfferID: integer (nullable = true)\n |-- UnitPrice: decimal(19,4) (nullable = true)\n |-- UnitPriceDiscount: decimal(19,4) (nullable = true)\n |-- LineTotal: decimal(38,6) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesOrderHeader  in Original Schema\n\nThe Schema of the table df_SalesOrderHeader is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- RevisionNumber: integer (nullable = true)\n |-- OrderDate: timestamp (nullable = true)\n |-- DueDate: timestamp (nullable = true)\n |-- ShipDate: timestamp (nullable = true)\n |-- Status: integer (nullable = true)\n |-- OnlineOrderFlag: boolean (nullable = true)\n |-- SalesOrderNumber: string (nullable = true)\n |-- PurchaseOrderNumber: string (nullable = true)\n |-- AccountNumber: string (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- SalesPersonID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- BillToAddressID: integer (nullable = true)\n |-- ShipToAddressID: integer (nullable = true)\n |-- ShipMethodID: integer (nullable = true)\n |-- CreditCardID: integer (nullable = true)\n |-- CreditCardApprovalCode: string (nullable = true)\n |-- CurrencyRateID: integer (nullable = true)\n |-- SubTotal: decimal(19,4) (nullable = true)\n |-- TaxAmt: decimal(19,4) (nullable = true)\n |-- Freight: decimal(19,4) (nullable = true)\n |-- TotalDue: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesOrderHeader  in transformed Schema\n\nThe Schema of the table df_SalesOrderHeader is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- RevisionNumber: integer (nullable = true)\n |-- OrderDate: date (nullable = true)\n |-- DueDate: date (nullable = true)\n |-- ShipDate: date (nullable = true)\n |-- Status: integer (nullable = true)\n |-- OnlineOrderFlag: boolean (nullable = true)\n |-- SalesOrderNumber: string (nullable = true)\n |-- PurchaseOrderNumber: string (nullable = true)\n |-- AccountNumber: string (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- SalesPersonID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- BillToAddressID: integer (nullable = true)\n |-- ShipToAddressID: integer (nullable = true)\n |-- ShipMethodID: integer (nullable = true)\n |-- CreditCardID: integer (nullable = true)\n |-- CreditCardApprovalCode: string (nullable = true)\n |-- CurrencyRateID: integer (nullable = true)\n |-- SubTotal: decimal(19,4) (nullable = true)\n |-- TaxAmt: decimal(19,4) (nullable = true)\n |-- Freight: decimal(19,4) (nullable = true)\n |-- TotalDue: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesOrderHeaderSalesReason  in Original Schema\n\nThe Schema of the table df_SalesOrderHeaderSalesReason is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- SalesReasonID: integer (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesOrderHeaderSalesReason  in transformed Schema\n\nThe Schema of the table df_SalesOrderHeaderSalesReason is :\nroot\n |-- SalesOrderID: integer (nullable = true)\n |-- SalesReasonID: integer (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesPerson  in Original Schema\n\nThe Schema of the table df_SalesPerson is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- SalesQuota: decimal(23,8) (nullable = true)\n |-- Bonus: decimal(19,4) (nullable = true)\n |-- CommissionPct: decimal(10,4) (nullable = true)\n |-- SalesYTD: decimal(19,4) (nullable = true)\n |-- SalesLastYear: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesPerson  in transformed Schema\n\nThe Schema of the table df_SalesPerson is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- SalesQuota: decimal(23,8) (nullable = true)\n |-- Bonus: decimal(19,4) (nullable = true)\n |-- CommissionPct: decimal(10,4) (nullable = true)\n |-- SalesYTD: decimal(19,4) (nullable = true)\n |-- SalesLastYear: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesPersonQuotaHistory  in Original Schema\n\nThe Schema of the table df_SalesPersonQuotaHistory is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- QuotaDate: timestamp (nullable = true)\n |-- SalesQuota: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesPersonQuotaHistory  in transformed Schema\n\nThe Schema of the table df_SalesPersonQuotaHistory is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- QuotaDate: date (nullable = true)\n |-- SalesQuota: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesReason  in Original Schema\n\nThe Schema of the table df_SalesReason is :\nroot\n |-- SalesReasonID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- ReasonType: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesReason  in transformed Schema\n\nThe Schema of the table df_SalesReason is :\nroot\n |-- SalesReasonID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- ReasonType: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesTaxRate  in Original Schema\n\nThe Schema of the table df_SalesTaxRate is :\nroot\n |-- SalesTaxRateID: integer (nullable = true)\n |-- StateProvinceID: integer (nullable = true)\n |-- TaxType: integer (nullable = true)\n |-- TaxRate: decimal(10,4) (nullable = true)\n |-- Name: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesTaxRate  in transformed Schema\n\nThe Schema of the table df_SalesTaxRate is :\nroot\n |-- SalesTaxRateID: integer (nullable = true)\n |-- StateProvinceID: integer (nullable = true)\n |-- TaxType: integer (nullable = true)\n |-- TaxRate: decimal(10,4) (nullable = true)\n |-- Name: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesTerritory  in Original Schema\n\nThe Schema of the table df_SalesTerritory is :\nroot\n |-- TerritoryID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- CountryRegionCode: string (nullable = true)\n |-- Group: string (nullable = true)\n |-- SalesYTD: decimal(19,4) (nullable = true)\n |-- SalesLastYear: decimal(19,4) (nullable = true)\n |-- CostYTD: decimal(19,4) (nullable = true)\n |-- CostLastYear: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesTerritory  in transformed Schema\n\nThe Schema of the table df_SalesTerritory is :\nroot\n |-- TerritoryID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- CountryRegionCode: string (nullable = true)\n |-- Group: string (nullable = true)\n |-- SalesYTD: decimal(19,4) (nullable = true)\n |-- SalesLastYear: decimal(19,4) (nullable = true)\n |-- CostYTD: decimal(19,4) (nullable = true)\n |-- CostLastYear: decimal(19,4) (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SalesTerritoryHistory  in Original Schema\n\nThe Schema of the table df_SalesTerritoryHistory is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- StartDate: timestamp (nullable = true)\n |-- EndDate: timestamp (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SalesTerritoryHistory  in transformed Schema\n\nThe Schema of the table df_SalesTerritoryHistory is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- TerritoryID: integer (nullable = true)\n |-- StartDate: date (nullable = true)\n |-- EndDate: date (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_ShoppingCartItem  in Original Schema\n\nThe Schema of the table df_ShoppingCartItem is :\nroot\n |-- ShoppingCartItemID: integer (nullable = true)\n |-- ShoppingCartID: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- DateCreated: timestamp (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_ShoppingCartItem  in transformed Schema\n\nThe Schema of the table df_ShoppingCartItem is :\nroot\n |-- ShoppingCartItemID: integer (nullable = true)\n |-- ShoppingCartID: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- DateCreated: date (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SpecialOffer  in Original Schema\n\nThe Schema of the table df_SpecialOffer is :\nroot\n |-- SpecialOfferID: integer (nullable = true)\n |-- Description: string (nullable = true)\n |-- DiscountPct: decimal(10,4) (nullable = true)\n |-- Type: string (nullable = true)\n |-- Category: string (nullable = true)\n |-- StartDate: timestamp (nullable = true)\n |-- EndDate: timestamp (nullable = true)\n |-- MinQty: integer (nullable = true)\n |-- MaxQty: integer (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SpecialOffer  in transformed Schema\n\nThe Schema of the table df_SpecialOffer is :\nroot\n |-- SpecialOfferID: integer (nullable = true)\n |-- Description: string (nullable = true)\n |-- DiscountPct: decimal(10,4) (nullable = true)\n |-- Type: string (nullable = true)\n |-- Category: string (nullable = true)\n |-- StartDate: date (nullable = true)\n |-- EndDate: date (nullable = true)\n |-- MinQty: integer (nullable = true)\n |-- MaxQty: integer (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_SpecialOfferProduct  in Original Schema\n\nThe Schema of the table df_SpecialOfferProduct is :\nroot\n |-- SpecialOfferID: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_SpecialOfferProduct  in transformed Schema\n\nThe Schema of the table df_SpecialOfferProduct is :\nroot\n |-- SpecialOfferID: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n\n df_Store  in Original Schema\n\nThe Schema of the table df_Store is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- SalesPersonID: integer (nullable = true)\n |-- Demographics: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: timestamp (nullable = true)\n\n\n df_Store  in transformed Schema\n\nThe Schema of the table df_Store is :\nroot\n |-- BusinessEntityID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- SalesPersonID: integer (nullable = true)\n |-- Demographics: string (nullable = true)\n |-- rowguid: string (nullable = true)\n |-- ModifiedDate: date (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transforming the date columns to date format\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "for file in df.keys():\n",
    "    print(\"\\n\",file,\" in Original Schema\")\n",
    "    print_schema(df[file],file)\n",
    "    for col in df[file].dtypes:\n",
    "        col_name = col[0]\n",
    "        col_type = col[1]\n",
    "        if 'date' in col_name or 'Date' in col_name:\n",
    "            df[file] = df[file].withColumn(col_name, to_date(col_name, 'MM/dd/yyyy'))\n",
    "\n",
    "    print(\"\\n\",file,\" in transformed Schema\")\n",
    "    print_schema(df[file],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29c60d62-9f10-4499-887b-fafba9ab6762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+------------+\n|CountryRegionCode|CurrencyCode|ModifiedDate|\n+-----------------+------------+------------+\n|               AE|         AED|  2014-02-08|\n|               AR|         ARS|  2014-02-08|\n|               AT|         ATS|  2014-02-08|\n|               AT|         EUR|  2008-04-30|\n|               AU|         AUD|  2014-02-08|\n+-----------------+------------+------------+\nonly showing top 5 rows\n\n+------------+-------------+--------------+--------+-------+------------+\n|CreditCardID|     CardType|    CardNumber|ExpMonth|ExpYear|ModifiedDate|\n+------------+-------------+--------------+--------+-------+------------+\n|           1| SuperiorCard|33332664695310|      11|   2006|  2013-07-29|\n|           2|  Distinguish|55552127249722|       8|   2005|  2013-12-05|\n|           3|ColonialVoice|77778344838353|       7|   2005|  2014-01-14|\n|           4|ColonialVoice|77774915718248|       7|   2006|  2013-05-20|\n|           5|        Vista|11114404600042|       4|   2005|  2013-02-01|\n+------------+-------------+--------------+--------+-------+------------+\nonly showing top 5 rows\n\n+------------+--------------------+------------+\n|CurrencyCode|                Name|ModifiedDate|\n+------------+--------------------+------------+\n|         AED|      Emirati Dirham|  2008-04-30|\n|         AFA|             Afghani|  2008-04-30|\n|         ALL|                 Lek|  2008-04-30|\n|         AMD|       Armenian Dram|  2008-04-30|\n|         ANG|Netherlands Antil...|  2008-04-30|\n+------------+--------------------+------------+\nonly showing top 5 rows\n\n+--------------+----------------+----------------+--------------+-----------+------------+------------+\n|CurrencyRateID|CurrencyRateDate|FromCurrencyCode|ToCurrencyCode|AverageRate|EndOfDayRate|ModifiedDate|\n+--------------+----------------+----------------+--------------+-----------+------------+------------+\n|             1|      2011-05-31|             USD|           ARS|     1.0000|      1.0002|  2011-05-31|\n|             2|      2011-05-31|             USD|           AUD|     1.5491|      1.5500|  2011-05-31|\n|             3|      2011-05-31|             USD|           BRL|     1.9379|      1.9419|  2011-05-31|\n|             4|      2011-05-31|             USD|           CAD|     1.4641|      1.4683|  2011-05-31|\n|             5|      2011-05-31|             USD|           CNY|     8.2781|      8.2784|  2011-05-31|\n+--------------+----------------+----------------+--------------+-----------+------------+------------+\nonly showing top 5 rows\n\n+----------+--------+-------+-----------+-------------+--------------------+------------+\n|CustomerID|PersonID|StoreID|TerritoryID|AccountNumber|             rowguid|ModifiedDate|\n+----------+--------+-------+-----------+-------------+--------------------+------------+\n|         1|       0|    934|          1|   AW00000001|3f5ae95e-b87d-4ae...|  2014-09-12|\n|         2|       0|   1028|          1|   AW00000002|e552f657-a9af-4a7...|  2014-09-12|\n|         3|       0|    642|          4|   AW00000003|130774b1-db21-4ef...|  2014-09-12|\n|         4|       0|    932|          4|   AW00000004|ff862851-1daa-404...|  2014-09-12|\n|         5|       0|   1026|          4|   AW00000005|83905bdc-6f5e-4f7...|  2014-09-12|\n+----------+--------+-------+-----------+-------------+--------------------+------------+\nonly showing top 5 rows\n\n+----------------+------------+------------+\n|BusinessEntityID|CreditCardID|ModifiedDate|\n+----------------+------------+------------+\n|             293|       17038|  2013-07-31|\n|             295|       15369|  2011-08-01|\n|             297|        8010|  2011-08-01|\n|             299|        5316|  2013-07-31|\n|             301|        6653|  2011-05-31|\n+----------------+------------+------------+\nonly showing top 5 rows\n\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+------------+\n|SalesOrderID|SalesOrderDetailID|CarrierTrackingNumber|OrderQty|ProductID|SpecialOfferID|UnitPrice|UnitPriceDiscount|  LineTotal|             rowguid|ModifiedDate|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+------------+\n|       43659|                 1|         4911-403C-98|       1|      776|             1|2024.9940|           0.0000|2024.994000|b207c96d-d9e6-402...|  2011-05-31|\n|       43659|                 2|         4911-403C-98|       3|      777|             1|2024.9940|           0.0000|6074.982000|7abb600d-1e77-41b...|  2011-05-31|\n|       43659|                 3|         4911-403C-98|       1|      778|             1|2024.9940|           0.0000|2024.994000|475cf8c6-49f6-486...|  2011-05-31|\n|       43659|                 4|         4911-403C-98|       1|      771|             1|2039.9940|           0.0000|2039.994000|04c4de91-5815-45d...|  2011-05-31|\n|       43659|                 5|         4911-403C-98|       1|      772|             1|2039.9940|           0.0000|2039.994000|5a74c7d2-e641-438...|  2011-05-31|\n+------------+------------------+---------------------+--------+---------+--------------+---------+-----------------+-----------+--------------------+------------+\nonly showing top 5 rows\n\n+------------+--------------+----------+----------+----------+------+---------------+----------------+-------------------+--------------+----------+-------------+-----------+---------------+---------------+------------+------------+----------------------+--------------+----------+---------+--------+----------+--------------------+------------+\n|SalesOrderID|RevisionNumber| OrderDate|   DueDate|  ShipDate|Status|OnlineOrderFlag|SalesOrderNumber|PurchaseOrderNumber| AccountNumber|CustomerID|SalesPersonID|TerritoryID|BillToAddressID|ShipToAddressID|ShipMethodID|CreditCardID|CreditCardApprovalCode|CurrencyRateID|  SubTotal|   TaxAmt| Freight|  TotalDue|             rowguid|ModifiedDate|\n+------------+--------------+----------+----------+----------+------+---------------+----------------+-------------------+--------------+----------+-------------+-----------+---------------+---------------+------------+------------+----------------------+--------------+----------+---------+--------+----------+--------------------+------------+\n|       43659|             8|2011-05-31|2011-06-12|2011-06-07|     5|          false|         SO43659|        PO522145787|10-4020-000676|     29825|          279|          5|            985|            985|           5|       16281|         105041Vi84182|             0|20565.6206|1971.5149|616.0984|23153.2339|79b65321-39ca-411...|  2011-06-07|\n|       43660|             8|2011-05-31|2011-06-12|2011-06-07|     5|          false|         SO43660|      PO18850127500|10-4020-000117|     29672|          279|          5|            921|            921|           5|        5618|         115213Vi29411|             0| 1294.2529| 124.2483| 38.8276| 1457.3288|738dc42d-d03b-48a...|  2011-06-07|\n|       43661|             8|2011-05-31|2011-06-12|2011-06-07|     5|          false|         SO43661|      PO18473189620|10-4020-000442|     29734|          282|          6|            517|            517|           5|        1346|           85274Vi6854|             4|32726.4786|3153.7696|985.5530|36865.8012|d91b9131-18a4-4a1...|  2011-06-07|\n|       43662|             8|2011-05-31|2011-06-12|2011-06-07|     5|          false|         SO43662|      PO18444174044|10-4020-000227|     29994|          282|          6|            482|            482|           5|       10456|         125295Vi53935|             4|28832.5289|2775.1646|867.2389|32474.9324|4a1ecfc0-cc3a-474...|  2011-06-07|\n|       43663|             8|2011-05-31|2011-06-12|2011-06-07|     5|          false|         SO43663|      PO18009186470|10-4020-000510|     29565|          276|          4|           1073|           1073|           5|        4322|          45303Vi22691|             0|  419.4589|  40.2681| 12.5838|  472.3108|9b1e7a40-6ae0-4ad...|  2011-06-07|\n+------------+--------------+----------+----------+----------+------+---------------+----------------+-------------------+--------------+----------+-------------+-----------+---------------+---------------+------------+------------+----------------------+--------------+----------+---------+--------+----------+--------------------+------------+\nonly showing top 5 rows\n\n+------------+-------------+------------+\n|SalesOrderID|SalesReasonID|ModifiedDate|\n+------------+-------------+------------+\n|       43697|            5|  2011-05-31|\n|       43697|            9|  2011-05-31|\n|       43702|            5|  2011-06-01|\n|       43702|            9|  2011-06-01|\n|       43703|            5|  2011-06-01|\n+------------+-------------+------------+\nonly showing top 5 rows\n\n+----------------+-----------+---------------+---------+-------------+------------+-------------+--------------------+------------+\n|BusinessEntityID|TerritoryID|     SalesQuota|    Bonus|CommissionPct|    SalesYTD|SalesLastYear|             rowguid|ModifiedDate|\n+----------------+-----------+---------------+---------+-------------+------------+-------------+--------------------+------------+\n|             274|          0|260714.28571429|   0.0000|       0.0000| 559697.5639|       0.0000|48754992-9ee0-4c0...|  2010-12-28|\n|             275|          2|300000.00000000|4100.0000|       0.0120|3763178.1787| 1750406.4785|1e0a7274-3064-4f5...|  2011-05-24|\n|             276|          4|250000.00000000|2000.0000|       0.0150|4251368.5497| 1439156.0291|4dd9eee4-8e81-4f8...|  2011-05-24|\n|             277|          3|250000.00000000|2500.0000|       0.0150|3189418.3662| 1997186.2037|39012928-bfec-424...|  2011-05-24|\n|             278|          6|250000.00000000| 500.0000|       0.0100|1453719.4653| 1620276.8966|7a0ae1ab-b283-40f...|  2011-05-24|\n+----------------+-----------+---------------+---------+-------------+------------+-------------+--------------------+------------+\nonly showing top 5 rows\n\n+----------------+----------+-----------+--------------------+------------+\n|BusinessEntityID| QuotaDate| SalesQuota|             rowguid|ModifiedDate|\n+----------------+----------+-----------+--------------------+------------+\n|             274|2011-05-31| 28000.0000|99109bbf-8693-458...|  2011-04-16|\n|             274|2011-08-31|  7000.0000|dfd01444-8900-461...|  2011-07-17|\n|             274|2011-12-01| 91000.0000|0a69f453-9689-4cc...|  2011-10-17|\n|             274|2012-02-29|140000.0000|da8d1458-5fb9-4c3...|  2012-01-15|\n|             274|2012-05-30| 70000.0000|760cef84-b980-417...|  2012-04-15|\n+----------------+----------+-----------+--------------------+------------+\nonly showing top 5 rows\n\n+-------------+--------------------+----------+------------+\n|SalesReasonID|                Name|ReasonType|ModifiedDate|\n+-------------+--------------------+----------+------------+\n|            1|               Price|     Other|  2008-04-30|\n|            2|        On Promotion| Promotion|  2008-04-30|\n|            3|Magazine Advertis...| Marketing|  2008-04-30|\n|            4|Television  Adver...| Marketing|  2008-04-30|\n|            5|        Manufacturer|     Other|  2008-04-30|\n+-------------+--------------------+----------+------------+\nonly showing top 5 rows\n\n+--------------+---------------+-------+-------+--------------------+--------------------+------------+\n|SalesTaxRateID|StateProvinceID|TaxType|TaxRate|                Name|             rowguid|ModifiedDate|\n+--------------+---------------+-------+-------+--------------------+--------------------+------------+\n|             1|              1|      1|14.0000|Canadian GST + Al...|683de5dd-521a-47d...|  2008-04-30|\n|             2|             57|      1|14.2500|Canadian GST + On...|05c4ffdb-4f84-4cd...|  2008-04-30|\n|             3|             63|      1|14.2500|Canadian GST + Qu...|d4edb557-56d7-403...|  2008-04-30|\n|             4|              1|      2| 7.0000|        Canadian GST|f0d76907-b433-453...|  2008-04-30|\n|             5|             57|      2| 7.0000|        Canadian GST|7e0e97a2-878b-476...|  2008-04-30|\n+--------------+---------------+-------+-------+--------------------+--------------------+------------+\nonly showing top 5 rows\n\n+-----------+---------+-----------------+-------------+-------------+-------------+-------+------------+--------------------+------------+\n|TerritoryID|     Name|CountryRegionCode|        Group|     SalesYTD|SalesLastYear|CostYTD|CostLastYear|             rowguid|ModifiedDate|\n+-----------+---------+-----------------+-------------+-------------+-------------+-------+------------+--------------------+------------+\n|          1|Northwest|               US|North America| 7887186.7882| 3298694.4938| 0.0000|      0.0000|43689a10-e30b-497...|  2008-04-30|\n|          2|Northeast|               US|North America| 2402176.8476| 3607148.9371| 0.0000|      0.0000|00fb7309-96cc-49e...|  2008-04-30|\n|          3|  Central|               US|North America| 3072175.1180| 3205014.0767| 0.0000|      0.0000|df6e7fd8-1a8d-468...|  2008-04-30|\n|          4|Southwest|               US|North America|10510853.8739| 5366575.7098| 0.0000|      0.0000|dc3e9ea0-7950-443...|  2008-04-30|\n|          5|Southeast|               US|North America| 2538667.2515| 3925071.4318| 0.0000|      0.0000|6dc4165a-5e4c-42d...|  2008-04-30|\n+-----------+---------+-----------------+-------------+-------------+-------------+-------+------------+--------------------+------------+\nonly showing top 5 rows\n\n+----------------+-----------+----------+----------+--------------------+------------+\n|BusinessEntityID|TerritoryID| StartDate|   EndDate|             rowguid|ModifiedDate|\n+----------------+-----------+----------+----------+--------------------+------------+\n|             275|          2|2011-05-31|2012-11-29|8563ce6a-00ff-47d...|  2012-11-22|\n|             275|          3|2012-11-30|2013-11-30|2f44304c-ee87-4c7...|  2012-11-23|\n|             276|          4|2011-05-31|2012-05-30|64bcb1b3-a793-40b...|  2011-05-24|\n|             277|          3|2011-05-31|2012-11-29|3e9f893d-5142-46c...|  2012-11-22|\n|             277|          2|2012-11-30|2013-11-30|132e4721-32dd-4a7...|  2012-11-23|\n+----------------+-----------+----------+----------+--------------------+------------+\nonly showing top 5 rows\n\n+------------------+--------------+--------+---------+-----------+------------+\n|ShoppingCartItemID|ShoppingCartID|Quantity|ProductID|DateCreated|ModifiedDate|\n+------------------+--------------+--------+---------+-----------+------------+\n|                 2|         14951|       3|      862| 2013-11-09|  2013-11-09|\n|                 4|         20621|       4|      881| 2013-11-09|  2013-11-09|\n|                 5|         20621|       7|      874| 2013-11-09|  2013-11-09|\n+------------------+--------------+--------+---------+-----------+------------+\n\n+--------------+--------------------+-----------+---------------+-----------+----------+----------+------+------+--------------------+------------+\n|SpecialOfferID|         Description|DiscountPct|           Type|   Category| StartDate|   EndDate|MinQty|MaxQty|             rowguid|ModifiedDate|\n+--------------+--------------------+-----------+---------------+-----------+----------+----------+------+------+--------------------+------------+\n|             1|         No Discount|     0.0000|    No Discount|No Discount|2011-05-01|2014-11-30|     0|     0|0290c4f5-191f-433...|  2011-04-01|\n|             2|Volume Discount 1...|     0.0200|Volume Discount|   Reseller|2011-05-31|2014-05-30|    11|    14|d7542ee7-15db-454...|  2011-05-01|\n|             3|Volume Discount 1...|     0.0500|Volume Discount|   Reseller|2011-05-31|2014-05-30|    15|    24|4bdbcc01-8cf7-40a...|  2011-05-01|\n|             4|Volume Discount 2...|     0.1000|Volume Discount|   Reseller|2011-05-31|2014-05-30|    25|    40|504b5e85-8f3f-4eb...|  2011-05-01|\n|             5|Volume Discount 4...|     0.1500|Volume Discount|   Reseller|2011-05-31|2014-05-30|    41|    60|677e1d9d-944f-4e8...|  2011-05-01|\n+--------------+--------------------+-----------+---------------+-----------+----------+----------+------+------+--------------------+------------+\nonly showing top 5 rows\n\n+--------------+---------+--------------------+------------+\n|SpecialOfferID|ProductID|             rowguid|ModifiedDate|\n+--------------+---------+--------------------+------------+\n|             1|      680|bb30b868-d86c-455...|  2011-04-01|\n|             1|      706|b3c9a4b1-2ae6-4cb...|  2011-04-01|\n|             1|      707|27b711fe-0b77-4ea...|  2011-04-01|\n|             1|      708|46cbb78b-246e-4d6...|  2011-04-01|\n|             1|      709|cf102aa0-055f-4d2...|  2011-04-01|\n+--------------+---------+--------------------+------------+\nonly showing top 5 rows\n\n+----------------+--------------------+-------------+--------------------+--------------------+------------+\n|BusinessEntityID|                Name|SalesPersonID|        Demographics|             rowguid|ModifiedDate|\n+----------------+--------------------+-------------+--------------------+--------------------+------------+\n|             292|Next-Door Bike Store|          279|<StoreSurvey xmln...|a22517e3-848d-4eb...|  2014-09-12|\n|             294|Professional Sale...|          276|<StoreSurvey xmln...|b50ca50b-c601-4a1...|  2014-09-12|\n|             296|      Riders Company|          277|<StoreSurvey xmln...|337c3688-1339-4e1...|  2014-09-12|\n|             298|  The Bike Mechanics|          275|<StoreSurvey xmln...|7894f278-f0c8-4d1...|  2014-09-12|\n|             300|   Nationwide Supply|          286|<StoreSurvey xmln...|c3fc9705-a8c4-4f3...|  2014-09-12|\n+----------------+--------------------+-------------+--------------------+--------------------+------------+\nonly showing top 5 rows\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the data of each tables to identify the timestamp column changed to dates\n",
    "for file in df.keys():\n",
    "    df[file].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14695f67-225e-41f1-89e5-817f70a4d2be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Writing the cleanedup data to silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecdb6b7d-b150-42af-9980-bde9dd2b7852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_CountryRegionCurrency/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_CountryRegionCurrency/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_CreditCard/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_CreditCard/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_Currency/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_Currency/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_CurrencyRate/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_CurrencyRate/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_Customer/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_Customer/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_PersonCreditCard/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_PersonCreditCard/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesOrderDetail/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesOrderDetail/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesOrderHeader/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesOrderHeader/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesOrderHeaderSalesReason/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesOrderHeaderSalesReason/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesPerson/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesPerson/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesPersonQuotaHistory/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesPersonQuotaHistory/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesReason/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesReason/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesTaxRate/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesTaxRate/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesTerritory/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesTerritory/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesTerritoryHistory/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SalesTerritoryHistory/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_ShoppingCartItem/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_ShoppingCartItem/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SpecialOffer/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SpecialOffer/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SpecialOfferProduct/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_SpecialOfferProduct/\nabfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_Store/\n✅ File saved successfully: abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/df_Store/\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n",
       "\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m---> 32\u001B[0m dilip\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'dilip' is not defined"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8875516628818281>, line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     31\u001B[0m check_nulls(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m],\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdf_SpecialOffer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m dilip\n",
        "\u001B[0;31mNameError\u001B[0m: name 'dilip' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Writing the cleanedup data to silver layer. \n",
    "\n",
    "silver_base_path = 'abfss://silver@dmgproductionadls2.dfs.core.windows.net/Sales/'\n",
    "bronze_base_path = 'abfss://bronze@dmgproductionadls2.dfs.core.windows.net/Sales/'\n",
    "\n",
    "for file in df.keys():\n",
    "    folder_path = f\"{silver_base_path}{file}/\"\n",
    "    df[file].write.mode(\"overwrite\").parquet(folder_path)\n",
    "    print(f\"✅ File saved successfully: {folder_path}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Sales Schema-Data Transformation-Bronze to Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}